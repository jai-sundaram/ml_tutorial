{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jai-sundaram/ml_tutorial/blob/main/my_decision_tree_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3cas2_1T98w"
      },
      "source": [
        "# Decision Tree Regression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CART - Classification and Regression Trees\n",
        "#encomppasses Classification Trees and Regression trees\n",
        "\n",
        "#first imagine that we are plotting graph, x - x1 (independent variable), y - x2 (independent variable). z - dependent variable\n",
        "#for now just looking at the two dimensional graph\n",
        "#we split the data points into numerous sections\n",
        "#how and where these splits are conducted is determined by the algorithm\n",
        "#involves looking at information entropy - simply put, when the split is performed, is the split increasing the amount of information we have about our points\n",
        "#is it adding some value to the way we want to group our points?\n",
        "#stops when it is possible to add any more information (leaves) to our setup\n",
        "#each split is called a leave, as said above\n",
        "#starting the drawing\n",
        "#first there is a split at x1 = 20\n",
        "#the c,ause created is x1 < 20\n",
        "#two branches, yes or no\n",
        "#another split is made at x2=170, only happens at points that are greater than 20\n",
        "#so under the first no branch, another clause is made where x2 <170\n",
        "#another split is made on the other side (x1 <20), at 200\n",
        "#so for the original yes  branch, there is a clause x2 < 200\n",
        "#another split happens where x2<170, at x1=40\n",
        "#so now a clause would be created under the 'yes' branch of x2 < 170, the clause would be x1<40\n",
        "#so now we want to see how to predict y for an observation that gets added to the scatterplot\n",
        "#dbtw, these splits added are called terminal leaves\n",
        "#to predict the y-value of the point added, we look at the terminal leave it is in\n",
        "#find the average of the terminal leave (averaging the y-value of the points inside the terminal leave)\n",
        "#now in the diagram, for each box under the certain outcome, we all we have to do is input the value that we get from finding the average of the split to which it corresponds\n",
        "#so now, whenever we have a new value, we just follow the diagram (which is called a decision tree), see where it falls, and then assign that corresponding value"
      ],
      "metadata": {
        "id": "LgNPaHT40B2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IODliia6U1xO"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpjZ43YlU8eI"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g16qFkFQVC35"
      },
      "source": [
        "## Training the Decision Tree Regression model on the whole dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQRGPTH3VcOn"
      },
      "source": [
        "## Predicting a new result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph8ExBj0VkIT"
      },
      "source": [
        "## Visualising the Decision Tree Regression results (higher resolution)"
      ]
    }
  ]
}