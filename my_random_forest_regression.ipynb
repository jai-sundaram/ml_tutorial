{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jai-sundaram/ml_tutorial/blob/main/my_random_forest_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeamvpPVXuS_"
      },
      "source": [
        "# Random Forest Regression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ensemble learning\n",
        "#random forest is a version of ensemble learning\n",
        "#ensemble learning is when you take multiple algorithms, or take the same algorithm multiple times and put them together to make something much more powerful than the original\n",
        "#Steps for random forest regression\n",
        "#fyi: k is just a random variable amount\n",
        "#Step 1: Pick at random K data points from the Training set\n",
        "#Step 2: Build the Decision Tree associated to these K data points\n",
        "#Step 3: Choose the number of trees you want to build and repeat steps 1-2.\n",
        "#Step 4: For a new data point, make each of the trees predict the value of y for the data point in question, and then assign the new data point the average of all the predicted y values from the trees\n",
        "#since we are not predicting based off of one tree but rather a 'forest' of trees, the accuracy of the prediction is improved\n",
        "#furthermore, ensemble alogrithms like this are more stable because any change in the dataset might impact only one tree, rather than the whole forest\n"
      ],
      "metadata": {
        "id": "P5l4xoPivdFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2wvZ7SKXzVC"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "qF077mHzzRIb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgbK_F8-X7em"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"/content/Position_Salaries.csv\")\n",
        "X = dataset.iloc[:, 1:-1]\n",
        "y = dataset.iloc[:,-1]"
      ],
      "metadata": {
        "id": "2MucfraTzU97"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4S2fyIBYDcu"
      },
      "source": [
        "## Training the Random Forest Regression model on the whole dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#builiding the random forest regression model\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "metadata": {
        "id": "EFL6Nf_vz5ru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IbsXbK3YM4M"
      },
      "source": [
        "## Predicting a new result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLqF9yMbYTon"
      },
      "source": [
        "## Visualising the Random Forest Regression results (higher resolution)"
      ]
    }
  ]
}